{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "547fc8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature-engine in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.23.5)\n",
      "Requirement already satisfied: pandas>=1.0.3 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.4.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (1.0.2)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from feature-engine) (0.13.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from pandas>=1.0.3->feature-engine) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from pandas>=1.0.3->feature-engine) (2.8.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from scikit-learn>=1.0.0->feature-engine) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from scikit-learn>=1.0.0->feature-engine) (1.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from statsmodels>=0.11.1->feature-engine) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature-engine) (3.0.9)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.11.1->feature-engine) (1.16.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (0.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.0.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\new folder\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "#Import necessary libraries for ML and Pre-Processing\n",
    "\n",
    "!pip install feature-engine \n",
    "!pip install imbalanced-learn\n",
    "\n",
    "from feature_engine.imputation import RandomSampleImputer\n",
    "\n",
    "\n",
    "#Importing the necessary libraries for EDA and model building\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#importing ML models from sklearn library\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "\n",
    "#Importing metrics functions from SK Learn\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "# # Used for Downloading MNIST\n",
    "\n",
    "# from sklearn.datasets import fetch_mldata\n",
    "\n",
    "\n",
    "\n",
    "# Used for Splitting Training and Test Sets\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "957e9dab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>MRI ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR1</td>\n",
       "      <td>Demented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR2</td>\n",
       "      <td>Demented</td>\n",
       "      <td>2</td>\n",
       "      <td>560</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OAS2_0002</td>\n",
       "      <td>OAS2_0002_MR3</td>\n",
       "      <td>Demented</td>\n",
       "      <td>3</td>\n",
       "      <td>1895</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
       "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
       "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
       "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
       "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
       "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
       "\n",
       "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
       "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
       "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
       "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
       "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
       "4  NaN  22.0  0.5  1698  0.701  1.034  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('dementia_dataset.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1cfa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nondemented</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nondemented</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demented</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Demented</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Demented</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Group  M/F  Age  EDUC  SES  MMSE  eTIV   nWBV    ASF  Class\n",
       "0  Nondemented    0   87    14  2.0  27.0  1987  0.696  0.883      0\n",
       "1  Nondemented    0   88    14  2.0  30.0  2004  0.681  0.876      0\n",
       "2     Demented    0   75    12  NaN  23.0  1678  0.736  1.046      1\n",
       "3     Demented    0   76    12  NaN  28.0  1738  0.713  1.010      1\n",
       "4     Demented    0   80    12  NaN  22.0  1698  0.701  1.034      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping the converted Group data points\n",
    "classes = ['Nondemented', 'Demented']\n",
    "dataset.drop(dataset.loc[dataset['Group'] == 'Converted'].index, inplace=True) # dataset.Group[dataset.Group == 'Converted'] = 'Nondemented' \n",
    "\n",
    "\n",
    "#Dropping the unwanted columns that won't be needing to include in our model\n",
    "dataset.drop(['Subject ID', 'MRI ID', 'Hand','CDR','MR Delay','Visit'], axis=1, inplace=True) # 'Visit','Age','EDUC','eTIV',...\n",
    "\n",
    "#Encoding binary variables\n",
    "dataset['M/F'] = dataset['M/F'].apply(lambda x: ['M', 'F'].index(x))\n",
    "\n",
    "#Encoding the class variable\n",
    "dataset['Class'] = [classes.index(group) for group in dataset['Group']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d68e2b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nondemented</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nondemented</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Demented</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1678</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Demented</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1738</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.010</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Demented</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1698</td>\n",
       "      <td>0.701</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Group  M/F  Age  EDUC  SES  MMSE  eTIV   nWBV    ASF  Class\n",
       "0  Nondemented    0   87    14  2.0  27.0  1987  0.696  0.883      0\n",
       "1  Nondemented    0   88    14  2.0  30.0  2004  0.681  0.876      0\n",
       "2     Demented    0   75    12  1.0  23.0  1678  0.736  1.046      1\n",
       "3     Demented    0   76    12  2.0  28.0  1738  0.713  1.010      1\n",
       "4     Demented    0   80    12  2.0  22.0  1698  0.701  1.034      1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from feature_engine.imputation import RandomSampleImputer\n",
    "\n",
    "imputer = RandomSampleImputer(\n",
    "        random_state=['SES','MMSE'],\n",
    "        seed='observation',\n",
    "        seeding_method='add'\n",
    "    )\n",
    "\n",
    "# fit the imputer\n",
    "imputer.fit(dataset)\n",
    "\n",
    "dataset = imputer.transform(dataset)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1394dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.Class\n",
    "dataset.drop(['Group','Class'], axis=1, inplace=True) # 'MR Delay''Visit',\n",
    "X = dataset\n",
    "\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c86b94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>76.711310</td>\n",
       "      <td>14.502976</td>\n",
       "      <td>2.529762</td>\n",
       "      <td>27.157738</td>\n",
       "      <td>1491.306548</td>\n",
       "      <td>0.730211</td>\n",
       "      <td>1.193595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496818</td>\n",
       "      <td>7.614793</td>\n",
       "      <td>2.900333</td>\n",
       "      <td>1.113958</td>\n",
       "      <td>3.838003</td>\n",
       "      <td>179.940267</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.140914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1357.000000</td>\n",
       "      <td>0.700750</td>\n",
       "      <td>1.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1475.000000</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>1.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1599.750000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>1.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              M/F         Age        EDUC         SES        MMSE  \\\n",
       "count  336.000000  336.000000  336.000000  336.000000  336.000000   \n",
       "mean     0.562500   76.711310   14.502976    2.529762   27.157738   \n",
       "std      0.496818    7.614793    2.900333    1.113958    3.838003   \n",
       "min      0.000000   60.000000    6.000000    1.000000    4.000000   \n",
       "25%      0.000000   71.000000   12.000000    2.000000   26.000000   \n",
       "50%      1.000000   76.000000   14.000000    2.000000   29.000000   \n",
       "75%      1.000000   82.000000   16.000000    3.000000   30.000000   \n",
       "max      1.000000   98.000000   23.000000    5.000000   30.000000   \n",
       "\n",
       "              eTIV        nWBV         ASF  \n",
       "count   336.000000  336.000000  336.000000  \n",
       "mean   1491.306548    0.730211    1.193595  \n",
       "std     179.940267    0.037313    0.140914  \n",
       "min    1106.000000    0.644000    0.876000  \n",
       "25%    1357.000000    0.700750    1.097500  \n",
       "50%    1475.000000    0.731000    1.190000  \n",
       "75%    1599.750000    0.756000    1.293000  \n",
       "max    2004.000000    0.837000    1.587000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1781f3",
   "metadata": {},
   "source": [
    "# adv analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7324c64b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "=============\n",
      "Training Accuracy: 1.0000\n",
      "Training Error Rate: 0.0000\n",
      "Training F1 Score: 1.0000\n",
      "Training Confusion Matrix:\n",
      "[[152   0]\n",
      " [  0 116]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9412\n",
      "Test Error Rate: 0.0588\n",
      "Test F1 Score: 0.9412\n",
      "Test Confusion Matrix:\n",
      "[[36  2]\n",
      " [ 2 28]]\n",
      "\n",
      "\n",
      "\n",
      "XGBoost\n",
      "=======\n",
      "Training Accuracy: 1.0000\n",
      "Training Error Rate: 0.0000\n",
      "Training F1 Score: 1.0000\n",
      "Training Confusion Matrix:\n",
      "[[152   0]\n",
      " [  0 116]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9559\n",
      "Test Error Rate: 0.0441\n",
      "Test F1 Score: 0.9559\n",
      "Test Confusion Matrix:\n",
      "[[36  2]\n",
      " [ 1 29]]\n",
      "\n",
      "\n",
      "\n",
      "SVC\n",
      "===\n",
      "Training Accuracy: 0.5672\n",
      "Training Error Rate: 0.4328\n",
      "Training F1 Score: 0.4105\n",
      "Training Confusion Matrix:\n",
      "[[152   0]\n",
      " [116   0]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5588\n",
      "Test Error Rate: 0.4412\n",
      "Test F1 Score: 0.4007\n",
      "Test Confusion Matrix:\n",
      "[[38  0]\n",
      " [30  0]]\n",
      "\n",
      "\n",
      "\n",
      "LDA\n",
      "===\n",
      "Training Accuracy: 0.8097\n",
      "Training Error Rate: 0.1903\n",
      "Training F1 Score: 0.8044\n",
      "Training Confusion Matrix:\n",
      "[[141  11]\n",
      " [ 40  76]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8676\n",
      "Test Error Rate: 0.1324\n",
      "Test F1 Score: 0.8630\n",
      "Test Confusion Matrix:\n",
      "[[38  0]\n",
      " [ 9 21]]\n",
      "\n",
      "\n",
      "\n",
      "Multiple Logistic\n",
      "=================\n",
      "Training Accuracy: 0.7948\n",
      "Training Error Rate: 0.2052\n",
      "Training F1 Score: 0.7902\n",
      "Training Confusion Matrix:\n",
      "[[137  15]\n",
      " [ 40  76]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9118\n",
      "Test Error Rate: 0.0882\n",
      "Test F1 Score: 0.9108\n",
      "Test Confusion Matrix:\n",
      "[[37  1]\n",
      " [ 5 25]]\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "===\n",
      "Training Accuracy: 0.7910\n",
      "Training Error Rate: 0.2090\n",
      "Training F1 Score: 0.7876\n",
      "Training Confusion Matrix:\n",
      "[[134  18]\n",
      " [ 38  78]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.6176\n",
      "Test Error Rate: 0.3824\n",
      "Test F1 Score: 0.6160\n",
      "Test Confusion Matrix:\n",
      "[[26 12]\n",
      " [14 16]]\n",
      "\n",
      "\n",
      "\n",
      "GausianNB\n",
      "=========\n",
      "Training Accuracy: 0.8209\n",
      "Training Error Rate: 0.1791\n",
      "Training F1 Score: 0.8166\n",
      "Training Confusion Matrix:\n",
      "[[141  11]\n",
      " [ 37  79]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8971\n",
      "Test Error Rate: 0.1029\n",
      "Test F1 Score: 0.8963\n",
      "Test Confusion Matrix:\n",
      "[[36  2]\n",
      " [ 5 25]]\n",
      "\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "==============\n",
      "Training Accuracy: 0.9963\n",
      "Training Error Rate: 0.0037\n",
      "Training F1 Score: 0.9963\n",
      "Training Confusion Matrix:\n",
      "[[152   0]\n",
      " [  1 115]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9265\n",
      "Test Error Rate: 0.0735\n",
      "Test F1 Score: 0.9266\n",
      "Test Confusion Matrix:\n",
      "[[35  3]\n",
      " [ 2 28]]\n",
      "\n",
      "\n",
      "\n",
      "Ridge\n",
      "=====\n",
      "Training Accuracy: 0.7948\n",
      "Training Error Rate: 0.2052\n",
      "Training F1 Score: 0.7902\n",
      "Training Confusion Matrix:\n",
      "[[137  15]\n",
      " [ 40  76]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9118\n",
      "Test Error Rate: 0.0882\n",
      "Test F1 Score: 0.9108\n",
      "Test Confusion Matrix:\n",
      "[[37  1]\n",
      " [ 5 25]]\n",
      "\n",
      "\n",
      "\n",
      "Lasso\n",
      "=====\n",
      "Training Accuracy: 0.8209\n",
      "Training Error Rate: 0.1791\n",
      "Training F1 Score: 0.8176\n",
      "Training Confusion Matrix:\n",
      "[[139  13]\n",
      " [ 35  81]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9412\n",
      "Test Error Rate: 0.0588\n",
      "Test F1 Score: 0.9409\n",
      "Test Confusion Matrix:\n",
      "[[37  1]\n",
      " [ 3 27]]\n",
      "\n",
      "\n",
      "\n",
      "Elastic-net\n",
      "===========\n",
      "Training Accuracy: 0.5746\n",
      "Training Error Rate: 0.4254\n",
      "Training F1 Score: 0.4272\n",
      "Training Confusion Matrix:\n",
      "[[152   0]\n",
      " [114   2]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.5588\n",
      "Test Error Rate: 0.4412\n",
      "Test F1 Score: 0.4007\n",
      "Test Confusion Matrix:\n",
      "[[38  0]\n",
      " [30  0]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(),\n",
    "    'SVC': SVC(probability=True),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'Multiple Logistic': LogisticRegression(solver='liblinear'),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'GausianNB':GaussianNB(),\n",
    "    'Gradient Boost':GradientBoostingClassifier(criterion = \"friedman_mse\"),\n",
    "    'Ridge': LogisticRegression(penalty='l2', C=1.0),\n",
    "    'Lasso': LogisticRegression(penalty='l1', C=1, solver='liblinear'),\n",
    "    'Elastic-net':LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1, solver='saga')\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train_feature, train_label)\n",
    "    \n",
    "    # Training set\n",
    "    train_pred = model.predict(train_feature)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_err = 1 - train_acc\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "    \n",
    "    # Test set\n",
    "    test_pred = model.predict(test_feature)\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_err = 1 - test_acc\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    \n",
    "    print(name)\n",
    "    print('='*len(name))\n",
    "    print(f'Training Accuracy: {train_acc:.4f}')\n",
    "    print(f'Training Error Rate: {train_err:.4f}')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Training Confusion Matrix:\\n{train_cm}')\n",
    "    print('\\n')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Error Rate: {test_err:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Balancing the data to reduce model bias towards one classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "554d152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 190, 1: 146})\n",
      "Counter({0: 190, 1: 190})\n"
     ]
    }
   ],
   "source": [
    "# Oversample and plot imbalanced dataset with SMOTE\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "# transform the dataset\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "print(counter)\n",
    "\n",
    "train_feature, test_feature, train_label, test_label = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "004c6824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>380.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.521053</td>\n",
       "      <td>76.571053</td>\n",
       "      <td>14.378947</td>\n",
       "      <td>2.537636</td>\n",
       "      <td>26.729512</td>\n",
       "      <td>1490.673684</td>\n",
       "      <td>0.728517</td>\n",
       "      <td>1.193931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500215</td>\n",
       "      <td>7.400542</td>\n",
       "      <td>2.863394</td>\n",
       "      <td>1.108911</td>\n",
       "      <td>4.066571</td>\n",
       "      <td>178.907027</td>\n",
       "      <td>0.036631</td>\n",
       "      <td>0.140646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1357.000000</td>\n",
       "      <td>0.699750</td>\n",
       "      <td>1.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.385095</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1475.000000</td>\n",
       "      <td>0.728000</td>\n",
       "      <td>1.189512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.207795</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1599.750000</td>\n",
       "      <td>0.753844</td>\n",
       "      <td>1.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              M/F         Age        EDUC         SES        MMSE  \\\n",
       "count  380.000000  380.000000  380.000000  380.000000  380.000000   \n",
       "mean     0.521053   76.571053   14.378947    2.537636   26.729512   \n",
       "std      0.500215    7.400542    2.863394    1.108911    4.066571   \n",
       "min      0.000000   60.000000    6.000000    1.000000    4.000000   \n",
       "25%      0.000000   71.000000   12.000000    2.000000   25.000000   \n",
       "50%      1.000000   76.000000   14.000000    2.385095   28.000000   \n",
       "75%      1.000000   81.000000   16.000000    3.207795   30.000000   \n",
       "max      1.000000   98.000000   23.000000    5.000000   30.000000   \n",
       "\n",
       "              eTIV        nWBV         ASF  \n",
       "count   380.000000  380.000000  380.000000  \n",
       "mean   1490.673684    0.728517    1.193931  \n",
       "std     178.907027    0.036631    0.140646  \n",
       "min    1106.000000    0.644000    0.876000  \n",
       "25%    1357.000000    0.699750    1.097500  \n",
       "50%    1475.000000    0.728000    1.189512  \n",
       "75%    1599.750000    0.753844    1.293000  \n",
       "max    2004.000000    0.837000    1.587000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f793d96a",
   "metadata": {},
   "source": [
    "regularization added to xg boost to reduce overfitting\n",
    "#Regularization: Adding a penalty term to the objective function during training can prevent the model from overfitting to the training data and reduce its complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9f7e5300",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "=============\n",
      "Training Accuracy: 1.0000\n",
      "Training Error Rate: 0.0000\n",
      "Training F1 Score: 1.0000\n",
      "Training Confusion Matrix:\n",
      "[[151   0]\n",
      " [  0 153]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9211\n",
      "Test Error Rate: 0.0789\n",
      "Test F1 Score: 0.9211\n",
      "Test Confusion Matrix:\n",
      "[[36  3]\n",
      " [ 3 34]]\n",
      "\n",
      "\n",
      "\n",
      "XGBoost\n",
      "=======\n",
      "Training Accuracy: 0.9934\n",
      "Training Error Rate: 0.0066\n",
      "Training F1 Score: 0.9934\n",
      "Training Confusion Matrix:\n",
      "[[151   0]\n",
      " [  2 151]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9342\n",
      "Test Error Rate: 0.0658\n",
      "Test F1 Score: 0.9342\n",
      "Test Confusion Matrix:\n",
      "[[37  2]\n",
      " [ 3 34]]\n",
      "\n",
      "\n",
      "\n",
      "SVC\n",
      "===\n",
      "Training Accuracy: 0.5000\n",
      "Training Error Rate: 0.5000\n",
      "Training F1 Score: 0.3468\n",
      "Training Confusion Matrix:\n",
      "[[  2 149]\n",
      " [  3 150]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.4868\n",
      "Test Error Rate: 0.5132\n",
      "Test F1 Score: 0.3408\n",
      "Test Confusion Matrix:\n",
      "[[ 1 38]\n",
      " [ 1 36]]\n",
      "\n",
      "\n",
      "\n",
      "LDA\n",
      "===\n",
      "Training Accuracy: 0.8289\n",
      "Training Error Rate: 0.1711\n",
      "Training F1 Score: 0.8278\n",
      "Training Confusion Matrix:\n",
      "[[138  13]\n",
      " [ 39 114]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8553\n",
      "Test Error Rate: 0.1447\n",
      "Test F1 Score: 0.8544\n",
      "Test Confusion Matrix:\n",
      "[[36  3]\n",
      " [ 8 29]]\n",
      "\n",
      "\n",
      "\n",
      "Multiple Logistic\n",
      "=================\n",
      "Training Accuracy: 0.8158\n",
      "Training Error Rate: 0.1842\n",
      "Training F1 Score: 0.8151\n",
      "Training Confusion Matrix:\n",
      "[[133  18]\n",
      " [ 38 115]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8553\n",
      "Test Error Rate: 0.1447\n",
      "Test F1 Score: 0.8552\n",
      "Test Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 6 31]]\n",
      "\n",
      "\n",
      "\n",
      "KNN\n",
      "===\n",
      "Training Accuracy: 0.7928\n",
      "Training Error Rate: 0.2072\n",
      "Training F1 Score: 0.7920\n",
      "Training Confusion Matrix:\n",
      "[[111  40]\n",
      " [ 23 130]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.6447\n",
      "Test Error Rate: 0.3553\n",
      "Test F1 Score: 0.6426\n",
      "Test Confusion Matrix:\n",
      "[[22 17]\n",
      " [10 27]]\n",
      "\n",
      "\n",
      "\n",
      "GausianNB\n",
      "=========\n",
      "Training Accuracy: 0.8388\n",
      "Training Error Rate: 0.1612\n",
      "Training F1 Score: 0.8378\n",
      "Training Confusion Matrix:\n",
      "[[139  12]\n",
      " [ 37 116]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8553\n",
      "Test Error Rate: 0.1447\n",
      "Test F1 Score: 0.8552\n",
      "Test Confusion Matrix:\n",
      "[[34  5]\n",
      " [ 6 31]]\n",
      "\n",
      "\n",
      "\n",
      "Gradient Boost\n",
      "==============\n",
      "Training Accuracy: 0.9868\n",
      "Training Error Rate: 0.0132\n",
      "Training F1 Score: 0.9868\n",
      "Training Confusion Matrix:\n",
      "[[151   0]\n",
      " [  4 149]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.9474\n",
      "Test Error Rate: 0.0526\n",
      "Test F1 Score: 0.9474\n",
      "Test Confusion Matrix:\n",
      "[[37  2]\n",
      " [ 2 35]]\n",
      "\n",
      "\n",
      "\n",
      "Ridge\n",
      "=====\n",
      "Training Accuracy: 0.8059\n",
      "Training Error Rate: 0.1941\n",
      "Training F1 Score: 0.8056\n",
      "Training Confusion Matrix:\n",
      "[[128  23]\n",
      " [ 36 117]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8421\n",
      "Test Error Rate: 0.1579\n",
      "Test F1 Score: 0.8421\n",
      "Test Confusion Matrix:\n",
      "[[33  6]\n",
      " [ 6 31]]\n",
      "\n",
      "\n",
      "\n",
      "Lasso\n",
      "=====\n",
      "Training Accuracy: 0.8553\n",
      "Training Error Rate: 0.1447\n",
      "Training F1 Score: 0.8550\n",
      "Training Confusion Matrix:\n",
      "[[136  15]\n",
      " [ 29 124]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.8947\n",
      "Test Error Rate: 0.1053\n",
      "Test F1 Score: 0.8947\n",
      "Test Confusion Matrix:\n",
      "[[35  4]\n",
      " [ 4 33]]\n",
      "\n",
      "\n",
      "\n",
      "Elastic-net\n",
      "===========\n",
      "Training Accuracy: 0.6974\n",
      "Training Error Rate: 0.3026\n",
      "Training F1 Score: 0.6964\n",
      "Training Confusion Matrix:\n",
      "[[114  37]\n",
      " [ 55  98]]\n",
      "\n",
      "\n",
      "Test Accuracy: 0.7237\n",
      "Test Error Rate: 0.2763\n",
      "Test F1 Score: 0.7220\n",
      "Test Confusion Matrix:\n",
      "[[31  8]\n",
      " [13 24]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': XGBClassifier(alpha=1),\n",
    "    'SVC': SVC(probability=True),\n",
    "    'LDA': LinearDiscriminantAnalysis(),\n",
    "    'Multiple Logistic': LogisticRegression(solver='liblinear'),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'GausianNB':GaussianNB(),\n",
    "    'Gradient Boost':GradientBoostingClassifier(criterion = \"friedman_mse\"),\n",
    "    'Ridge': LogisticRegression(penalty='l2', C=1.0),\n",
    "    'Lasso': LogisticRegression(penalty='l1', C=1, solver='liblinear'),\n",
    "    'Elastic-net':LogisticRegression(penalty='elasticnet', l1_ratio=0.5, C=1, solver='saga')\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(train_feature, train_label)\n",
    "    \n",
    "    # Training set\n",
    "    train_pred = model.predict(train_feature)\n",
    "    train_acc = accuracy_score(train_label, train_pred)\n",
    "    train_err = 1 - train_acc\n",
    "    train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "    train_cm = confusion_matrix(train_label, train_pred)\n",
    "    \n",
    "    # Test set\n",
    "    test_pred = model.predict(test_feature)\n",
    "    test_acc = accuracy_score(test_label, test_pred)\n",
    "    test_err = 1 - test_acc\n",
    "    test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "    test_cm = confusion_matrix(test_label, test_pred)\n",
    "    \n",
    "    print(name)\n",
    "    print('='*len(name))\n",
    "    print(f'Training Accuracy: {train_acc:.4f}')\n",
    "    print(f'Training Error Rate: {train_err:.4f}')\n",
    "    print(f'Training F1 Score: {train_f1:.4f}')\n",
    "    print(f'Training Confusion Matrix:\\n{train_cm}')\n",
    "    print('\\n')\n",
    "    print(f'Test Accuracy: {test_acc:.4f}')\n",
    "    print(f'Test Error Rate: {test_err:.4f}')\n",
    "    print(f'Test F1 Score: {test_f1:.4f}')\n",
    "    print(f'Test Confusion Matrix:\\n{test_cm}')\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cadedfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c20bcc82",
   "metadata": {},
   "source": [
    "# Randomized grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9d1152b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}\n",
      "Best cross-validation score:  0.880712788259958\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "rf_best = RandomForestClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                  max_depth=grid_search.best_params_['max_depth'], \n",
    "                                  min_samples_split=grid_search.best_params_['min_samples_split'],\n",
    "                                  min_samples_leaf=grid_search.best_params_['min_samples_leaf'],\n",
    "                                  max_features=grid_search.best_params_['max_features'])\n",
    "rf_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = rf_best.score(train_feature, train_label)\n",
    "test_acc = rf_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28760b8c",
   "metadata": {},
   "source": [
    "# use bootstrap to reduce overfitting to rf after using grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "225e439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.base import clone\n",
    "\n",
    "\n",
    "# Define the model with bootstrapping\n",
    "model = RandomForestClassifier(n_estimators=100, \n",
    "                               max_features='sqrt', \n",
    "                               min_samples_leaf= 1,\n",
    "                               min_samples_split= 6,\n",
    "                               max_depth=30, \n",
    "                               random_state=42)\n",
    "\n",
    "# Train the model with bootstrapping\n",
    "n_bootstraps = 10\n",
    "bootstrapped_models = []\n",
    "for i in range(n_bootstraps):\n",
    "    X_boot, y_boot = resample(train_feature, train_label, random_state=i)\n",
    "    model_i = clone(model)\n",
    "    model_i.fit(X_boot, y_boot)\n",
    "    bootstrapped_models.append(model_i)\n",
    "\n",
    "# Make predictions by averaging the bootstrapped models\n",
    "y_pred = np.mean([model.predict(test_feature) for model in bootstrapped_models], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5fde76f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9802631578947368\n",
      "Train F1 score: 0.9802631578947368\n",
      "Test accuracy: 0.9078947368421053\n",
      "Test F1 score: 0.9078468235788012\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Calculate accuracy and f1 score on train set\n",
    "train_pred = np.mean([model.predict(train_feature) for model in bootstrapped_models], axis=0)\n",
    "train_pred = np.round(train_pred)\n",
    "train_pred[train_pred < 0.5] = 0\n",
    "train_pred[train_pred >= 0.5] = 1\n",
    "train_acc = accuracy_score(train_label, train_pred)\n",
    "train_f1 = f1_score(train_label, train_pred, average='weighted')\n",
    "\n",
    "# Calculate accuracy and f1 score on test set\n",
    "test_pred = np.mean([model.predict(test_feature) for model in bootstrapped_models], axis=0)\n",
    "test_pred = np.round(test_pred)\n",
    "test_pred[test_pred < 0.5] = 0\n",
    "test_pred[test_pred >= 0.5] = 1\n",
    "test_acc = accuracy_score(test_label, test_pred)\n",
    "test_f1 = f1_score(test_label, test_pred, average='weighted')\n",
    "\n",
    "print(\"Train accuracy:\", train_acc)\n",
    "print(\"Train F1 score:\", train_f1)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "print(\"Test F1 score:\", test_f1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8730f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'subsample': 0.6, 'random_state': 42, 'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 7, 'learning_rate': 0.15}\n",
      "Best cross-validation score:  0.8979781420765027\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.9342105263157895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the Gradient Boosting model\n",
    "gb = GradientBoostingClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.05, 0.1, 0.15],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'random_state': [42],\n",
    "    \n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=gb, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "gb_best = GradientBoostingClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                                      max_depth=grid_search.best_params_['max_depth'], \n",
    "                                      learning_rate=grid_search.best_params_['learning_rate'],\n",
    "                                     subsample= grid_search.best_params_['subsample'],\n",
    "                                     min_samples_split= grid_search.best_params_['min_samples_split'],\n",
    "                                     min_samples_leaf =grid_search.best_params_['min_samples_leaf'] ,\n",
    "                                     max_features =grid_search.best_params_['max_features'] ,\n",
    "                                     random_state =grid_search.best_params_['random_state'] \n",
    "                                    )\n",
    "gb_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = gb_best.score(train_feature, train_label)\n",
    "test_acc = gb_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cd32ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'n_neighbors': 5, 'p': 1, 'weights': 'distance'}\n",
      "Best cross-validation score:  0.7993989071038252\n",
      "Training accuracy:  1.0\n",
      "Test accuracy:  0.8289473684210527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=knn, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "knn_best = KNeighborsClassifier(n_neighbors=grid_search.best_params_['n_neighbors'], \n",
    "                                 weights=grid_search.best_params_['weights'], \n",
    "                                 p=grid_search.best_params_['p'])\n",
    "knn_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = knn_best.score(train_feature, train_label)\n",
    "test_acc = knn_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64392b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'subsample': 0.9, 'n_estimators': 300, 'max_depth': 30, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 0.8}\n",
      "Best cross-validation score:  0.8814754098360655\n",
      "Training accuracy:  0.9572368421052632\n",
      "Test accuracy:  0.881578947368421\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the XGBoost model\n",
    "xgb = XGBClassifier(alpha=1)\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = grid_search = RandomizedSearchCV(estimator=xgb, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "xgb_best = XGBClassifier(n_estimators=grid_search.best_params_['n_estimators'], \n",
    "                         max_depth=grid_search.best_params_['max_depth'], \n",
    "                         learning_rate=grid_search.best_params_['learning_rate'],\n",
    "                         subsample=grid_search.best_params_['subsample'],\n",
    "                         colsample_bytree=grid_search.best_params_['colsample_bytree'],\n",
    "                         gamma=grid_search.best_params_['gamma'],\n",
    "                        alpha=1)\n",
    "xgb_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = xgb_best.score(train_feature, train_label)\n",
    "test_acc = xgb_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95894486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'var_smoothing': 1e-09, 'priors': [0.3, 0.7]}\n",
      "Best cross-validation score:  0.8585792349726777\n",
      "Training accuracy:  0.8618421052631579\n",
      "Test accuracy:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the Gaussian Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7],\n",
    "    'priors': [None, [0.3, 0.7], [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3]]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search =  RandomizedSearchCV(estimator=nb, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "nb_best = GaussianNB(var_smoothing=grid_search.best_params_['var_smoothing'], \n",
    "                     priors=grid_search.best_params_['priors'])\n",
    "nb_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = nb_best.score(train_feature, train_label)\n",
    "test_acc = nb_best.score(test_feature, test_label)\n",
    "\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fde5cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'solver': 'lsqr', 'shrinkage': 'auto', 'n_components': None}\n",
      "Best cross-validation score:  0.8090710382513662\n",
      "Training accuracy:  0.8092105263157895\n",
      "Test accuracy:  0.868421052631579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the LDA model\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'shrinkage': [None, 'auto', 0.1, 0.5, 0.9],\n",
    "    'n_components': [None, 1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = grid_search = RandomizedSearchCV(estimator=lda, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(train_feature, train_label)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n",
    "# Use the best hyperparameters to fit the model on the training set\n",
    "lda_best = LinearDiscriminantAnalysis(solver=grid_search.best_params_['solver'], \n",
    "                                      shrinkage=grid_search.best_params_['shrinkage'], \n",
    "                                      n_components=grid_search.best_params_['n_components'])\n",
    "lda_best.fit(train_feature, train_label)\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = lda_best.score(train_feature, train_label)\n",
    "test_acc = lda_best.score(test_feature, test_label)\n",
    "\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "print(\"Test accuracy: \", test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4ea030",
   "metadata": {},
   "source": [
    "# more if continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6c8572ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda\n",
      "Training accuracy:  0.8256578947368421\n",
      "Training precision:  0.8377240143369176\n",
      "Training recall:  0.8262779725576765\n",
      "Training f1-score:  0.8242717070031739\n",
      "Training error rate:  0.17434210526315785\n",
      "Training sensitivity:  0.7320261437908496\n",
      "Training specificity:  0.9205298013245033\n",
      "Training time:  0.09971261024475098\n",
      "\n",
      "\n",
      "Test accuracy:  0.881578947368421\n",
      "Test precision:  0.8892045454545454\n",
      "Test recall:  0.8797643797643797\n",
      "Test f1-score:  0.8805657412257726\n",
      "Test error rate:  0.11842105263157898\n",
      "Test sensitivity:  0.8108108108108109\n",
      "Test specificity:  0.9487179487179487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = lda_best.score(train_feature, train_label)\n",
    "test_acc = lda_best.score(test_feature, test_label)\n",
    "\n",
    "print('lda')\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "\n",
    "\n",
    "# Make predictions on training and test data\n",
    "train_preds = lda_best.predict(train_feature)\n",
    "test_preds = lda_best.predict(test_feature)\n",
    "\n",
    "# Calculate the confusion matrix for training and test sets\n",
    "train_cm = confusion_matrix(train_label, train_preds)\n",
    "test_cm = confusion_matrix(test_label, test_preds)\n",
    "\n",
    "# Calculate precision, recall, f1-score, and support for training and test sets\n",
    "train_precision = precision_score(train_label, train_preds, average='macro')\n",
    "train_recall = recall_score(train_label, train_preds, average='macro')\n",
    "train_f1 = f1_score(train_label, train_preds, average='macro')\n",
    "\n",
    "test_precision = precision_score(test_label, test_preds, average='macro')\n",
    "test_recall = recall_score(test_label, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_label, test_preds, average='macro')\n",
    "\n",
    "# Calculate error rate for training and test sets\n",
    "train_error_rate = 1 - train_acc\n",
    "test_error_rate = 1 - test_acc\n",
    "\n",
    "# Calculate sensitivity and specificity for training and test sets\n",
    "train_sensitivity = train_cm[1, 1] / (train_cm[1, 1] + train_cm[1, 0])\n",
    "train_specificity = train_cm[0, 0] / (train_cm[0, 0] + train_cm[0, 1])\n",
    "\n",
    "test_sensitivity = test_cm[1, 1] / (test_cm[1, 1] + test_cm[1, 0])\n",
    "test_specificity = test_cm[0, 0] / (test_cm[0, 0] + test_cm[0, 1])\n",
    "\n",
    "# Calculate the time taken to fit the model on the training data\n",
    "start_time = time.time()\n",
    "xgb_best.fit(train_feature, train_label)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Print the evaluation metrics for both training and test sets\n",
    "\n",
    "\n",
    "print(\"Training precision: \", train_precision)\n",
    "print(\"Training recall: \", train_recall)\n",
    "print(\"Training f1-score: \", train_f1)\n",
    "print(\"Training error rate: \", train_error_rate)\n",
    "print(\"Training sensitivity: \", train_sensitivity)\n",
    "print(\"Training specificity: \", train_specificity)\n",
    "print(\"Training time: \", train_time)\n",
    "print('\\n')\n",
    "print(\"Test accuracy: \", test_acc)\n",
    "print(\"Test precision: \", test_precision)\n",
    "print(\"Test recall: \", test_recall)\n",
    "print(\"Test f1-score: \", test_f1)\n",
    "print(\"Test error rate: \", test_error_rate)\n",
    "print(\"Test sensitivity: \", test_sensitivity)\n",
    "print(\"Test specificity: \", test_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81046a7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb\n",
      "Training accuracy:  0.993421052631579\n",
      "Training precision:  0.9934640522875817\n",
      "Training recall:  0.9934640522875817\n",
      "Training f1-score:  0.993421052631579\n",
      "Training error rate:  0.006578947368421018\n",
      "Training sensitivity:  0.9869281045751634\n",
      "Training specificity:  1.0\n",
      "Training time:  800.9320330619812\n",
      "\n",
      "\n",
      "Test accuracy:  0.9078947368421053\n",
      "Test precision:  0.9078947368421053\n",
      "Test recall:  0.9081774081774082\n",
      "Test f1-score:  0.907878787878788\n",
      "Test error rate:  0.09210526315789469\n",
      "Test sensitivity:  0.918918918918919\n",
      "Test specificity:  0.8974358974358975\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = xgb_best.score(train_feature, train_label)\n",
    "test_acc = xgb_best.score(test_feature, test_label)\n",
    "\n",
    "print('xgb')\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "\n",
    "\n",
    "# Make predictions on training and test data\n",
    "train_preds = xgb_best.predict(train_feature)\n",
    "test_preds = xgb_best.predict(test_feature)\n",
    "\n",
    "# Calculate the confusion matrix for training and test sets\n",
    "train_cm = confusion_matrix(train_label, train_preds)\n",
    "test_cm = confusion_matrix(test_label, test_preds)\n",
    "\n",
    "# Calculate precision, recall, f1-score, and support for training and test sets\n",
    "train_precision = precision_score(train_label, train_preds, average='macro')\n",
    "train_recall = recall_score(train_label, train_preds, average='macro')\n",
    "train_f1 = f1_score(train_label, train_preds, average='macro')\n",
    "\n",
    "test_precision = precision_score(test_label, test_preds, average='macro')\n",
    "test_recall = recall_score(test_label, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_label, test_preds, average='macro')\n",
    "\n",
    "# Calculate error rate for training and test sets\n",
    "train_error_rate = 1 - train_acc\n",
    "test_error_rate = 1 - test_acc\n",
    "\n",
    "# Calculate sensitivity and specificity for training and test sets\n",
    "train_sensitivity = train_cm[1, 1] / (train_cm[1, 1] + train_cm[1, 0])\n",
    "train_specificity = train_cm[0, 0] / (train_cm[0, 0] + train_cm[0, 1])\n",
    "\n",
    "test_sensitivity = test_cm[1, 1] / (test_cm[1, 1] + test_cm[1, 0])\n",
    "test_specificity = test_cm[0, 0] / (test_cm[0, 0] + test_cm[0, 1])\n",
    "\n",
    "# Calculate the time taken to fit the model on the training data\n",
    "start_time = time.time()\n",
    "xgb_best.fit(train_feature, train_label)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Print the evaluation metrics for both training and test sets\n",
    "print(\"Training precision: \", train_precision)\n",
    "print(\"Training recall: \", train_recall)\n",
    "print(\"Training f1-score: \", train_f1)\n",
    "print(\"Training error rate: \", train_error_rate)\n",
    "print(\"Training sensitivity: \", train_sensitivity)\n",
    "print(\"Training specificity: \", train_specificity)\n",
    "print(\"Training time: \", train_time)\n",
    "print('\\n')\n",
    "print(\"Test accuracy: \", test_acc)\n",
    "print(\"Test precision: \", test_precision)\n",
    "print(\"Test recall: \", test_recall)\n",
    "print(\"Test f1-score: \", test_f1)\n",
    "print(\"Test error rate: \", test_error_rate)\n",
    "print(\"Test sensitivity: \", test_sensitivity)\n",
    "print(\"Test specificity: \", test_specificity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "04837ad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gaussian nb\n",
      "Training accuracy:  0.8618421052631579\n",
      "Training precision:  0.8618361251785482\n",
      "Training recall:  0.8618361251785482\n",
      "Training f1-score:  0.8618361251785482\n",
      "Training error rate:  0.13815789473684215\n",
      "Training sensitivity:  0.8627450980392157\n",
      "Training specificity:  0.8609271523178808\n",
      "Training time:  0.0983121395111084\n",
      "\n",
      "\n",
      "Test accuracy:  0.868421052631579\n",
      "Test precision:  0.8717770034843205\n",
      "Test recall:  0.8697158697158698\n",
      "Test f1-score:  0.8683298683298684\n",
      "Test error rate:  0.13157894736842102\n",
      "Test sensitivity:  0.918918918918919\n",
      "Test specificity:  0.8205128205128205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "import time\n",
    "\n",
    "# Evaluate the training and test accuracy of the model\n",
    "train_acc = nb_best.score(train_feature, train_label)\n",
    "test_acc = nb_best.score(test_feature, test_label)\n",
    "\n",
    "print('gaussian nb')\n",
    "print(\"Training accuracy: \", train_acc)\n",
    "\n",
    "\n",
    "# Make predictions on training and test data\n",
    "train_preds = nb_best.predict(train_feature)\n",
    "test_preds = nb_best.predict(test_feature)\n",
    "\n",
    "# Calculate the confusion matrix for training and test sets\n",
    "train_cm = confusion_matrix(train_label, train_preds)\n",
    "test_cm = confusion_matrix(test_label, test_preds)\n",
    "\n",
    "# Calculate precision, recall, f1-score, and support for training and test sets\n",
    "train_precision = precision_score(train_label, train_preds, average='macro')\n",
    "train_recall = recall_score(train_label, train_preds, average='macro')\n",
    "train_f1 = f1_score(train_label, train_preds, average='macro')\n",
    "\n",
    "test_precision = precision_score(test_label, test_preds, average='macro')\n",
    "test_recall = recall_score(test_label, test_preds, average='macro')\n",
    "test_f1 = f1_score(test_label, test_preds, average='macro')\n",
    "\n",
    "# Calculate error rate for training and test sets\n",
    "train_error_rate = 1 - train_acc\n",
    "test_error_rate = 1 - test_acc\n",
    "\n",
    "# Calculate sensitivity and specificity for training and test sets\n",
    "train_sensitivity = train_cm[1, 1] / (train_cm[1, 1] + train_cm[1, 0])\n",
    "train_specificity = train_cm[0, 0] / (train_cm[0, 0] + train_cm[0, 1])\n",
    "\n",
    "test_sensitivity = test_cm[1, 1] / (test_cm[1, 1] + test_cm[1, 0])\n",
    "test_specificity = test_cm[0, 0] / (test_cm[0, 0] + test_cm[0, 1])\n",
    "\n",
    "# Calculate the time taken to fit the model on the training data\n",
    "start_time = time.time()\n",
    "xgb_best.fit(train_feature, train_label)\n",
    "end_time = time.time()\n",
    "train_time = end_time - start_time\n",
    "\n",
    "# Print the evaluation metrics for both training and test sets\n",
    "print(\"Training precision: \", train_precision)\n",
    "print(\"Training recall: \", train_recall)\n",
    "print(\"Training f1-score: \", train_f1)\n",
    "print(\"Training error rate: \", train_error_rate)\n",
    "print(\"Training sensitivity: \", train_sensitivity)\n",
    "print(\"Training specificity: \", train_specificity)\n",
    "print(\"Training time: \", train_time)\n",
    "print('\\n')\n",
    "print(\"Test accuracy: \", test_acc)\n",
    "print(\"Test precision: \", test_precision)\n",
    "print(\"Test recall: \", test_recall)\n",
    "print(\"Test f1-score: \", test_f1)\n",
    "print(\"Test error rate: \", test_error_rate)\n",
    "print(\"Test sensitivity: \", test_sensitivity)\n",
    "print(\"Test specificity: \", test_specificity)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05615a5f",
   "metadata": {},
   "source": [
    "the XGBClassifier model has higher accuracy, precision, recall, and f1-score for both the training and test sets, while also having a lower error rate. The model also trained faster than the GaussianNB model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee1994d",
   "metadata": {},
   "source": [
    "# confusion matrix for Gaussian nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5be1528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn import metrics\n",
    "\n",
    "model = GaussianNB(var_smoothing=1e-09, \n",
    "                     priors=[0.3, 0.7])\n",
    "model.fit(train_feature, train_label)\n",
    "\n",
    "# Confusion matrix for the training set\n",
    "predicted_train = model.predict(train_feature)\n",
    "cm_train = metrics.confusion_matrix(train_label, predicted_train)\n",
    "cm_display_train = metrics.ConfusionMatrixDisplay(confusion_matrix=cm_train, display_labels=[0, 1])\n",
    "cm_display_train.plot()\n",
    "plt.title('Confusion Matrix for Training Set')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for the test set\n",
    "predicted_test = model.predict(test_feature)\n",
    "cm_test = metrics.confusion_matrix(test_label, predicted_test)\n",
    "cm_display_test = metrics.ConfusionMatrixDisplay(confusion_matrix=cm_test, display_labels=[0, 1])\n",
    "cm_display_test.plot()\n",
    "plt.title('Confusion Matrix for Test Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "709bdeb2",
   "metadata": {},
   "source": [
    "Best hyperparameters:  {'var_smoothing': 1e-09, 'priors': [0.3, 0.7]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30e9809",
   "metadata": {},
   "source": [
    "# best hyperparameters for whole data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddd4e8f",
   "metadata": {},
   "source": [
    "# run the upper part to take orginal X and y, then run below code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c84c3a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:  {'var_smoothing': 1e-07, 'priors': None}\n",
      "Best cross-validation score:  0.8482001755926252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Create the Gaussian Naive Bayes model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7],\n",
    "    'priors': [None, [0.3, 0.7], [0.4, 0.6], [0.5, 0.5], [0.6, 0.4], [0.7, 0.3]]\n",
    "}\n",
    "\n",
    "# Perform a grid search over the parameter grid using 5-fold cross-validation\n",
    "grid_search = RandomizedSearchCV(estimator=nb, param_distributions=param_grid, n_iter=100, cv=5, \n",
    "                               scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "grid_search.fit(X,y)\n",
    "\n",
    "# Print the best hyperparameters and corresponding cross-validation score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: \", grid_search.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6a77ff6",
   "metadata": {},
   "source": [
    "nb = GaussianNB(var_smoothing= 1e-07, priors= None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d89e25a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M/F</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>336.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.562500</td>\n",
       "      <td>76.711310</td>\n",
       "      <td>14.502976</td>\n",
       "      <td>2.529762</td>\n",
       "      <td>27.157738</td>\n",
       "      <td>1491.306548</td>\n",
       "      <td>0.730211</td>\n",
       "      <td>1.193595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.496818</td>\n",
       "      <td>7.614793</td>\n",
       "      <td>2.900333</td>\n",
       "      <td>1.113958</td>\n",
       "      <td>3.838003</td>\n",
       "      <td>179.940267</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>0.140914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1357.000000</td>\n",
       "      <td>0.700750</td>\n",
       "      <td>1.097500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1475.000000</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>1.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1599.750000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>1.293000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.837000</td>\n",
       "      <td>1.587000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              M/F         Age        EDUC         SES        MMSE  \\\n",
       "count  336.000000  336.000000  336.000000  336.000000  336.000000   \n",
       "mean     0.562500   76.711310   14.502976    2.529762   27.157738   \n",
       "std      0.496818    7.614793    2.900333    1.113958    3.838003   \n",
       "min      0.000000   60.000000    6.000000    1.000000    4.000000   \n",
       "25%      0.000000   71.000000   12.000000    2.000000   26.000000   \n",
       "50%      1.000000   76.000000   14.000000    2.000000   29.000000   \n",
       "75%      1.000000   82.000000   16.000000    3.000000   30.000000   \n",
       "max      1.000000   98.000000   23.000000    5.000000   30.000000   \n",
       "\n",
       "              eTIV        nWBV         ASF  \n",
       "count   336.000000  336.000000  336.000000  \n",
       "mean   1491.306548    0.730211    1.193595  \n",
       "std     179.940267    0.037313    0.140914  \n",
       "min    1106.000000    0.644000    0.876000  \n",
       "25%    1357.000000    0.700750    1.097500  \n",
       "50%    1475.000000    0.731000    1.190000  \n",
       "75%    1599.750000    0.756000    1.293000  \n",
       "max    2004.000000    0.837000    1.587000  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "355aac4a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[36  2]\n",
      " [ 4 26]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92        38\n",
      "           1       0.93      0.87      0.90        30\n",
      "\n",
      "    accuracy                           0.91        68\n",
      "   macro avg       0.91      0.91      0.91        68\n",
      "weighted avg       0.91      0.91      0.91        68\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "nb_best = GaussianNB(var_smoothing= 1e-07, priors= None)\n",
    "nb_best.fit(train_feature, train_label)\n",
    "\n",
    "nb_best_predict = nb_best.predict(test_feature)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(test_label, nb_best_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(test_label, nb_best_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa741e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[35  4]\n",
      " [ 5 32]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        39\n",
      "           1       0.89      0.86      0.88        37\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.88      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "xgb_best_predict = xgb_best.predict(test_feature)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(test_label, xgb_best_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(test_label, xgb_best_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53cd412f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[37  2]\n",
      " [ 8 29]]\n",
      "\n",
      "\n",
      "=== Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88        39\n",
      "           1       0.94      0.78      0.85        37\n",
      "\n",
      "    accuracy                           0.87        76\n",
      "   macro avg       0.88      0.87      0.87        76\n",
      "weighted avg       0.88      0.87      0.87        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "lda_best_predict = lda_best.predict(test_feature)\n",
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(test_label, lda_best_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(test_label, lda_best_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
